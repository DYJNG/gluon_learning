{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: \n",
      "[[[[  0.   1.   2.   3.]\n",
      "   [  4.   5.   6.   7.]\n",
      "   [  8.   9.  10.  11.]\n",
      "   [ 12.  13.  14.  15.]]]]\n",
      "<NDArray 1x1x4x4 @cpu(0)> \n",
      "\n",
      "weight: \n",
      "[[[[ 0.  1.  2.]\n",
      "   [ 3.  4.  5.]\n",
      "   [ 6.  7.  8.]]]]\n",
      "<NDArray 1x1x3x3 @cpu(0)> \n",
      "\n",
      "bias: \n",
      "[ 1.]\n",
      "<NDArray 1 @cpu(0)> \n",
      "\n",
      "output: \n",
      "[[[[ 259.  295.]\n",
      "   [ 403.  439.]]]]\n",
      "<NDArray 1x1x2x2 @cpu(0)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyjng/anaconda3/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead\n",
      "  import OpenSSL.SSL\n"
     ]
    }
   ],
   "source": [
    "from mxnet import nd\n",
    "\n",
    "# input format is batch x channel x height x width, there batch and channel all 1\n",
    "# weight format is output _channels x in_channels x height x weight, there input_channel and output_channel all 1\n",
    "data = nd.arange(16).reshape((1, 1, 4, 4))\n",
    "w = nd.arange(9).reshape((1, 1, 3, 3))\n",
    "b = nd.array([1])\n",
    "out = nd.Convolution(data, w, b, kernel = w.shape[2:], num_filter = w.shape[0])\n",
    "\n",
    "print('input:', data, '\\n\\nweight:', w, '\\n\\nbias:', b, '\\n\\noutput:', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: \n",
      "[[[[  0.   1.   2.   3.]\n",
      "   [  4.   5.   6.   7.]\n",
      "   [  8.   9.  10.  11.]\n",
      "   [ 12.  13.  14.  15.]]]]\n",
      "<NDArray 1x1x4x4 @cpu(0)> \n",
      "\n",
      "weight: \n",
      "[[[[ 0.  1.  2.]\n",
      "   [ 3.  4.  5.]\n",
      "   [ 6.  7.  8.]]]]\n",
      "<NDArray 1x1x3x3 @cpu(0)> \n",
      "\n",
      "bias: \n",
      "[ 1.]\n",
      "<NDArray 1 @cpu(0)> \n",
      "\n",
      "output: \n",
      "[[[[  74.  155.]\n",
      "   [ 280.  439.]]]]\n",
      "<NDArray 1x1x2x2 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "out = nd.Convolution(data, w, b, kernel = w.shape[2:], num_filter = w.shape[0],\n",
    "                    stride = (2, 2), pad = (1, 1))\n",
    "# pad(1, 1) add a row in top, add a column in left\n",
    "print('input:', data, '\\n\\nweight:', w, '\\n\\nbias:', b, '\\n\\noutput:', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: \n",
      "[[[[  0.   1.   2.   3.]\n",
      "   [  4.   5.   6.   7.]\n",
      "   [  8.   9.  10.  11.]\n",
      "   [ 12.  13.  14.  15.]]\n",
      "\n",
      "  [[ 16.  17.  18.  19.]\n",
      "   [ 20.  21.  22.  23.]\n",
      "   [ 24.  25.  26.  27.]\n",
      "   [ 28.  29.  30.  31.]]]]\n",
      "<NDArray 1x2x4x4 @cpu(0)> \n",
      "\n",
      "weight: \n",
      "[[[[  0.   1.   2.]\n",
      "   [  3.   4.   5.]\n",
      "   [  6.   7.   8.]]\n",
      "\n",
      "  [[  9.  10.  11.]\n",
      "   [ 12.  13.  14.]\n",
      "   [ 15.  16.  17.]]]]\n",
      "<NDArray 1x2x3x3 @cpu(0)> \n",
      "\n",
      "bias: \n",
      "[ 1.]\n",
      "<NDArray 1 @cpu(0)> \n",
      "\n",
      "output: \n",
      "[[[[ 2794.  2947.]\n",
      "   [ 3406.  3559.]]]]\n",
      "<NDArray 1x1x2x2 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "data = nd.arange(32).reshape((1, 2, 4, 4))\n",
    "w = nd.arange(18).reshape((1, 2, 3, 3))\n",
    "\n",
    "out = nd.Convolution(data, w, b, kernel = w.shape[2:], num_filter = w.shape[0])\n",
    "\n",
    "print('input:', data, '\\n\\nweight:', w, '\\n\\nbias:', b, '\\n\\noutput:', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: \n",
      "[[[[  0.   1.   2.   3.]\n",
      "   [  4.   5.   6.   7.]\n",
      "   [  8.   9.  10.  11.]\n",
      "   [ 12.  13.  14.  15.]]\n",
      "\n",
      "  [[ 16.  17.  18.  19.]\n",
      "   [ 20.  21.  22.  23.]\n",
      "   [ 24.  25.  26.  27.]\n",
      "   [ 28.  29.  30.  31.]]]]\n",
      "<NDArray 1x2x4x4 @cpu(0)> \n",
      "\n",
      "weight: \n",
      "[[[[  0.   1.   2.]\n",
      "   [  3.   4.   5.]\n",
      "   [  6.   7.   8.]]\n",
      "\n",
      "  [[  9.  10.  11.]\n",
      "   [ 12.  13.  14.]\n",
      "   [ 15.  16.  17.]]]\n",
      "\n",
      "\n",
      " [[[ 18.  19.  20.]\n",
      "   [ 21.  22.  23.]\n",
      "   [ 24.  25.  26.]]\n",
      "\n",
      "  [[ 27.  28.  29.]\n",
      "   [ 30.  31.  32.]\n",
      "   [ 33.  34.  35.]]]]\n",
      "<NDArray 2x2x3x3 @cpu(0)> \n",
      "\n",
      "bias: \n",
      "[ 1.  2.]\n",
      "<NDArray 2 @cpu(0)> \n",
      "\n",
      "output: \n",
      "[[[[ 2794.  2947.]\n",
      "   [ 3406.  3559.]]\n",
      "\n",
      "  [[ 7007.  7484.]\n",
      "   [ 8915.  9392.]]]]\n",
      "<NDArray 1x2x2x2 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "data = nd.arange(32).reshape((1, 2, 4, 4))\n",
    "w = nd.arange(36).reshape((2, 2, 3, 3))\n",
    "b = nd.array([1, 2])\n",
    "\n",
    "out = nd.Convolution(data, w, b, kernel = w.shape[2:], num_filter = w.shape[0])\n",
    "\n",
    "print('input:', data, '\\n\\nweight:', w, '\\n\\nbias:', b, '\\n\\noutput:', out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: \n",
      "[[[[  0.   1.   2.   3.]\n",
      "   [  4.   5.   6.   7.]\n",
      "   [  8.   9.  10.  11.]\n",
      "   [ 12.  13.  14.  15.]]\n",
      "\n",
      "  [[ 16.  17.  18.  19.]\n",
      "   [ 20.  21.  22.  23.]\n",
      "   [ 24.  25.  26.  27.]\n",
      "   [ 28.  29.  30.  31.]]]]\n",
      "<NDArray 1x2x4x4 @cpu(0)> \n",
      "\n",
      "max pooling: \n",
      "[[[[  5.   6.   7.]\n",
      "   [  9.  10.  11.]\n",
      "   [ 13.  14.  15.]]\n",
      "\n",
      "  [[ 21.  22.  23.]\n",
      "   [ 25.  26.  27.]\n",
      "   [ 29.  30.  31.]]]]\n",
      "<NDArray 1x2x3x3 @cpu(0)> \n",
      "\n",
      "avg pooling: \n",
      "[[[[  2.5   4.5]\n",
      "   [ 10.5  12.5]]\n",
      "\n",
      "  [[ 18.5  20.5]\n",
      "   [ 26.5  28.5]]]]\n",
      "<NDArray 1x2x2x2 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "data = nd.arange(32).reshape((1, 2, 4, 4))\n",
    "\n",
    "max_pool = nd.Pooling(data = data, pool_type = 'max', kernel = (2, 2), stride = (1, 1))\n",
    "avg_pool = nd.Pooling(data = data, pool_type = 'avg', kernel = (2, 2), stride = (2, 2))\n",
    "\n",
    "print('data:', data, '\\n\\nmax pooling:', max_pool, '\\n\\navg pooling:', avg_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234 39\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils import load_data_fashion_mnist\n",
    "\n",
    "batch_size = 256\n",
    "train_data, test_data = load_data_fashion_mnist(batch_size)\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gpu(0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default use GPU, if without GPU then use CPU\n",
    "import mxnet as mx\n",
    "\n",
    "try:\n",
    "    ctx = mx.gpu()\n",
    "    _ = nd.zeros((1,), ctx = ctx)\n",
    "except:\n",
    "    ctx = mx.cpu()\n",
    "ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet\n",
    "    --2 conv layers, 2 dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_scale = .01\n",
    "\n",
    "# output channel = 20, kernel = (5, 5)\n",
    "W1 = nd.random_normal(shape = (20, 1, 5, 5), scale = weight_scale, ctx = ctx)\n",
    "b1 = nd.zeros(W1.shape[0], ctx = ctx)\n",
    "\n",
    "# output channel = 50, kernel = (3, 3)\n",
    "W2 = nd.random_normal(shape = (50, 20, 3, 3), scale = weight_scale, ctx = ctx)\n",
    "b2 = nd.zeros(W2.shape[0], ctx = ctx)\n",
    "\n",
    "# output = 128\n",
    "W3 = nd.random_normal(shape = (1250, 128), scale = weight_scale, ctx = ctx)\n",
    "b3 = nd.zeros(W3.shape[1], ctx = ctx)\n",
    "\n",
    "# output = 10\n",
    "W4 = nd.random_normal(shape = (128, 10), scale = weight_scale, ctx = ctx)\n",
    "b4 = nd.zeros(W4.shape[1], ctx = ctx)\n",
    "\n",
    "params = [W1, b1, W2, b2, W3, b3, W4, b4]\n",
    "for param in params:\n",
    "    param.attach_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# verbose used to debug\n",
    "def net(X, verbose = False):\n",
    "    X = X.as_in_context(W1.context)   # W1.context equals mx.gpu()\n",
    "    # first conv layer\n",
    "    h1_conv = nd.Convolution(data = X, weight = W1, bias = b1,\n",
    "                             kernel = W1.shape[2:], num_filter = W1.shape[0])\n",
    "    h1_activation = nd.relu(h1_conv)\n",
    "    h1 = nd.Pooling(data = h1_activation, pool_type = 'max', kernel = (2, 2), stride = (2, 2))\n",
    "    # second conv layer\n",
    "    h2_conv = nd.Convolution(data = h1, weight = W2, bias = b2,\n",
    "                             kernel = W2.shape[2:], num_filter = W2.shape[0])\n",
    "    h2_activation = nd.relu(h2_conv)\n",
    "    h2 = nd.Pooling(data = h2_activation, pool_type = 'max', kernel = (2, 2), stride = (2, 2))\n",
    "    h2_flat = nd.flatten(h2)  # too important\n",
    "    # first dense\n",
    "    h3_linear = nd.dot(h2_flat, W3) + b3\n",
    "    h3 = nd.relu(h3_linear)\n",
    "    # second dense\n",
    "    h4_linear = nd.dot(h3, W4) + b4\n",
    "    if verbose:\n",
    "        print('lst conv block:', h1.shape)\n",
    "        print('2nd conv block:', h2.shape)\n",
    "        print('1st dense:', h3.shape)\n",
    "        print('2nd dense:', h4_linear.shape)\n",
    "        print('output:', h4_linear)\n",
    "    return h4_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lst conv block: (256, 20, 12, 12)\n",
      "2nd conv block: (256, 50, 5, 5)\n",
      "1st dense: (256, 128)\n",
      "2nd dense: (256, 10)\n",
      "output: \n",
      "[[ -1.25888808e-04   1.71888860e-05   1.23100952e-04 ...,   7.24935308e-05\n",
      "    8.06554308e-05   1.10734043e-04]\n",
      " [ -1.70488565e-04   4.61007294e-05   1.51696251e-04 ...,   9.41563194e-05\n",
      "    1.82403484e-04   1.73743480e-04]\n",
      " [ -1.24564744e-04  -9.15816781e-06   2.91839388e-05 ...,   1.68508661e-04\n",
      "    6.87505744e-05   7.67239981e-05]\n",
      " ..., \n",
      " [ -1.92659660e-04  -1.84186938e-05   4.50565203e-05 ...,   1.54259193e-04\n",
      "    1.71014544e-04   1.36011484e-04]\n",
      " [ -1.53804373e-04   3.90572495e-06   6.65578118e-05 ...,   3.82953804e-05\n",
      "    1.01694750e-04   9.99176846e-05]\n",
      " [ -1.39973097e-04   7.38169911e-06   1.24147031e-04 ...,   1.02233811e-04\n",
      "    1.03171726e-04   1.47112325e-04]]\n",
      "<NDArray 256x10 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "for data, _ in train_data:\n",
    "    net(data, verbose = True)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.302016, Train acc 0.109876, Test acc 0.219351\n",
      "Epoch 1, Loss: 1.345695, Train acc 0.506243, Test acc 0.722356\n",
      "Epoch 2, Loss: 0.658532, Train acc 0.745326, Test acc 0.781550\n",
      "Epoch 3, Loss: 0.524083, Train acc 0.800114, Test acc 0.816707\n",
      "Epoch 4, Loss: 0.458224, Train acc 0.829377, Test acc 0.851262\n"
     ]
    }
   ],
   "source": [
    "from mxnet import autograd as ag\n",
    "from utils import SGD, accuracy, evaluate_accuracy\n",
    "from mxnet import gluon\n",
    "\n",
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "learning_rate = .2\n",
    "\n",
    "for epoch in range(5):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    for data, label in train_data:\n",
    "        label = label.as_in_context(ctx)\n",
    "        with ag.record():\n",
    "            output = net(data)\n",
    "            loss = softmax_cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        SGD(params, learning_rate / batch_size)\n",
    "        \n",
    "        train_loss += nd.mean(loss).asscalar()\n",
    "        train_acc += accuracy(output, label)\n",
    "        \n",
    "    test_acc = evaluate_accuracy(test_data, net, ctx)\n",
    "    print('Epoch %d, Loss: %f, Train acc %f, Test acc %f' % (\n",
    "        epoch, train_loss / len(train_data), train_acc / len(train_data), test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SoftmaxCrossEntropy contains softmax() and cross_entropy()\n",
    "# help(gluon.loss.SoftmaxCrossEntropyLoss())\n",
    "gluon.loss.SoftmaxCrossEntropyLoss??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234 39\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
