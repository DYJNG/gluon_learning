{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 25 00:02:08 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 384.130                Driver Version: 384.130                   |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:29:00.0  On |                  N/A |\r\n",
      "|  0%   43C    P8    19W / 280W |   4443MiB / 11169MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1340      G   /usr/lib/xorg/Xorg                           204MiB |\r\n",
      "|    0      2239      G   compiz                                       138MiB |\r\n",
      "|    0      7096      C   /home/dyjng/anaconda3/bin/python            1581MiB |\r\n",
      "|    0      7135      C   /home/dyjng/anaconda3/bin/python            2515MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "\n",
    "def vgg_block(num_convs, channels):\n",
    "    out = nn.Sequential()\n",
    "    for _ in range(num_convs):\n",
    "        out.add(\n",
    "            nn.Conv2D(channels = channels, kernel_size = 3, \n",
    "                     padding = 1, activation = 'relu')\n",
    "        )\n",
    "    out.add(nn.MaxPool2D(pool_size = 2, strides = 2))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 128, 8, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mxnet import nd\n",
    "\n",
    "blk = vgg_block(2, 128)\n",
    "blk.initialize()\n",
    "x = nd.random.uniform(shape = (2, 3, 16, 16))\n",
    "y = blk(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_stack(architecture):\n",
    "    out = nn.Sequential()\n",
    "    for (num_convs, channels) in architecture:\n",
    "        out.add(vgg_block(num_convs, channels))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_output = 10\n",
    "architecture = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))\n",
    "net = nn.Sequential()\n",
    "# add name_scope on the outermost Sequential\n",
    "with net.name_scope():\n",
    "    net.add(\n",
    "        vgg_stack(architecture), \n",
    "        nn.Flatten(), \n",
    "        nn.Dense(4096, activation = 'relu'), \n",
    "        nn.Dropout(.5), \n",
    "        nn.Dense(4096, activation = 'relu'), \n",
    "        nn.Dropout(.5), \n",
    "        nn.Dense(num_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training on  gpu(0)\n",
      "Epoch 0. Loss: 0.921, Train acc 0.66, Test acc 0.83, Time 57.4 sec\n",
      "Epoch 1. Loss: 0.399, Train acc 0.85, Test acc 0.88, Time 57.2 sec\n",
      "Epoch 2. Loss: 0.325, Train acc 0.88, Test acc 0.89, Time 57.2 sec\n",
      "Epoch 3. Loss: 0.283, Train acc 0.89, Test acc 0.90, Time 57.1 sec\n",
      "Epoch 4. Loss: 0.250, Train acc 0.91, Test acc 0.91, Time 57.6 sec\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "from mxnet import gluon\n",
    "from mxnet import init\n",
    "\n",
    "train_data, test_data = utils.load_data_fashion_mnist(\n",
    "    batch_size = 64, resize = 96)\n",
    "\n",
    "ctx = utils.try_gpu()\n",
    "net.initialize(ctx = ctx, init = init.Xavier())\n",
    "\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(net.collect_params(), \n",
    "                       'sgd', {'learning_rate': 0.05})\n",
    "utils.train(train_data, test_data, net, loss, trainer, ctx, num_epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
