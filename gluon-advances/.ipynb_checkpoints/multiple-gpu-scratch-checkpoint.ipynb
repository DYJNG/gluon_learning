{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 30 00:55:25 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 384.130                Driver Version: 384.130                   |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:29:00.0  On |                  N/A |\r\n",
      "| 18%   53C    P2    61W / 280W |    834MiB / 11169MiB |      5%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1330      G   /usr/lib/xorg/Xorg                           178MiB |\r\n",
      "|    0      2209      G   compiz                                       166MiB |\r\n",
      "|    0     28986      C   /home/dyjng/anaconda3/bin/python             477MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyjng/anaconda3/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead\n",
      "  import OpenSSL.SSL\n"
     ]
    }
   ],
   "source": [
    "from mxnet import nd\n",
    "from mxnet import gluon\n",
    "\n",
    "# initialize parameters\n",
    "scale = .01\n",
    "W1 = nd.random.normal(shape = (20, 1, 3, 3)) * scale\n",
    "b1 = nd.zeros(shape = 20)\n",
    "W2 = nd.random.normal(shape = (50, 20, 5, 5)) * scale\n",
    "b2 = nd.zeros(shape = 50)\n",
    "W3 = nd.random.normal(shape = (800, 128)) * scale\n",
    "b3 = nd.zeros(128)\n",
    "W4 = nd.random.normal(shape = (128, 10))\n",
    "b4 = nd.zeros(shape = 10)\n",
    "params = [W1, b1, W2, b2, W3, b3, W4, b4]\n",
    "\n",
    "# network and loss\n",
    "def lenet(X, params):\n",
    "    # 1st conv\n",
    "    h1_conv = nd.Convolution(data = X, weight = params[0], bias = params[1], \n",
    "                             kernel = (3, 3), num_filter = 20)\n",
    "    h1_activation = nd.relu(h1_conv)\n",
    "    h1 = nd.Pooling(data = h1_activation, pool_type = 'avg', \n",
    "                    kernel = (2, 2), stride = (2, 2))\n",
    "    # 2nd conv\n",
    "    h2_conv = nd.Convolution(data = h1, weight = params[2], bias = params[3], \n",
    "                             kernel = (5, 5), num_filter = 50)\n",
    "    h2_activation = nd.relu(h2_conv)\n",
    "    h2 = nd.Pooling(data = h2_activation, pool_type = 'avg', \n",
    "                    kernel = (2, 2), stride = (2,2))\n",
    "    h2_flat = nd.flatten(h2)\n",
    "    # 1st dense\n",
    "    h3_linear = nd.dot(h2_flat, params[4]) + params[5]\n",
    "    h3 = nd.relu(h3_linear)\n",
    "    # 2nd dense\n",
    "    yhat = nd.dot(h3, params[6]) + params[7]\n",
    "    return yhat\n",
    "\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1 weight =  \n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "<NDArray 20 @gpu(0)>\n",
      "b1 grad =  \n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "<NDArray 20 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "from mxnet import gpu\n",
    "from mxnet import cpu\n",
    "\n",
    "def get_params(params, ctx):\n",
    "    new_params = [p.copyto(ctx) for p in params]\n",
    "    for p in new_params:\n",
    "        p.attach_grad()\n",
    "    return new_params\n",
    "\n",
    "# copy params to GPU(0)\n",
    "new_params = get_params(params, gpu(0))\n",
    "print('b1 weight = ', new_params[1])\n",
    "print('b1 grad = ', new_params[1].grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: [\n",
      "[[ 1.  1.]]\n",
      "<NDArray 1x2 @gpu(0)>, \n",
      "[[ 2.  2.]]\n",
      "<NDArray 1x2 @cpu(0)>]\n",
      "After: [\n",
      "[[ 3.  3.]]\n",
      "<NDArray 1x2 @gpu(0)>, \n",
      "[[ 3.  3.]]\n",
      "<NDArray 1x2 @cpu(0)>]\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "def allreduce(data):\n",
    "    # sum on data[0].context, and then broadcast\n",
    "    for i in range(1, len(data)):\n",
    "        data[0][:] += data[i].copyto(data[0].context)\n",
    "    for i in range(1, len(data)):\n",
    "        data[0].copyto(data[i])\n",
    "        \n",
    "# data = [nd.ones((1, 2), ctx = mx.gpu(i)) * (i + 1) for i in range(2)]\n",
    "data = [nd.ones((1, 2), ctx = gpu(0)), nd.ones((1, 2), ctx = cpu(0)) * 2]\n",
    "print('Before:', data)\n",
    "allreduce(data)\n",
    "print('After:', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  \n",
      "[[  0.   1.   2.   3.]\n",
      " [  4.   5.   6.   7.]\n",
      " [  8.   9.  10.  11.]\n",
      " [ 12.  13.  14.  15.]]\n",
      "<NDArray 4x4 @gpu(0)>\n",
      "Load into [gpu(0), cpu(0)]\n",
      "Output: [\n",
      "[[ 0.  1.  2.  3.]\n",
      " [ 4.  5.  6.  7.]]\n",
      "<NDArray 2x4 @gpu(0)>, \n",
      "[[  8.   9.  10.  11.]\n",
      " [ 12.  13.  14.  15.]]\n",
      "<NDArray 2x4 @cpu(0)>]\n"
     ]
    }
   ],
   "source": [
    "def split_and_load(data, ctx):\n",
    "    n, k = data.shape[0], len(ctx)\n",
    "    m = n // k\n",
    "    assert m * k == n, '# examples is not divided by # devices'\n",
    "    return [data[i * m : (i + 1) * m].as_in_context(ctx[i]) for i in range(k)]\n",
    "\n",
    "batch = nd.arange(16).reshape((4, 4))\n",
    "batch = batch.as_in_context(gpu(0))\n",
    "# ctx = [gpu(0), gpu(1)]\n",
    "ctx = [gpu(0), cpu(0)]\n",
    "splitted = split_and_load(batch, ctx)\n",
    "\n",
    "print('Input: ', batch)\n",
    "print('Load into', ctx)\n",
    "print('Output:', splitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(params[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import  autograd as ag\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "\n",
    "def train_batch(data, label, params, ctx, lr):\n",
    "    # split the data batch and load them on GPUs\n",
    "    data_list = split_and_load(data, ctx)\n",
    "    label_list = split_and_load(label, ctx)\n",
    "    # run forward on each GPU\n",
    "    with ag.record():\n",
    "        losses = [loss(lenet(X, W), Y) \n",
    "                  for X, Y, W in zip(data_list, label_list, params)]\n",
    "    # run backward on each GPU\n",
    "    for l in losses:\n",
    "        l.backward()\n",
    "    # aggregate gradient over GPUs\n",
    "    for i in range(len(params[0])):  ######## W1 b1 W2 b2 ... W4 b4  8ä¸ª ######\n",
    "        allreduce([params[c][i].grad for c in range(len(ctx))])\n",
    "    # update params with SGD on each GPU\n",
    "    for p in params:\n",
    "        utils.SGD(p, lr / data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "def train(num_gpus, batch_size, lr):\n",
    "    train_data, test_data = utils.load_data_fashion_mnist(batch_size)\n",
    "    \n",
    "#     ctx = [gpu(i) for i in range(num_gpus)]\n",
    "    try:\n",
    "        num_gpus > 2\n",
    "    except:\n",
    "        print('Not more than 1 GPU and 1 CPU')\n",
    "#     assert num_gpus < 3\n",
    "    if num_gpus == 1:\n",
    "        ctx = [gpu(0)]\n",
    "    elif num_gpus == 2:\n",
    "        ctx = [gpu(0), cpu(0)]\n",
    "    else:\n",
    "        return 0\n",
    "    print('Running on', ctx)\n",
    "    \n",
    "    # copy params to all GPUs\n",
    "    dev_params = [get_params(params, c) for c in ctx]   # shape is 2 x 8\n",
    "    \n",
    "    for epoch in range(5):\n",
    "        # train\n",
    "        start = time()\n",
    "        for data, label in train_data:\n",
    "            train_batch(data, label, dev_params, ctx, lr)\n",
    "        nd.waitall()\n",
    "        print('Epoch %d, training time = %.1f sec' % \n",
    "              (epoch, time() - start))\n",
    "        \n",
    "        # validating on GPU 0\n",
    "        net = lambda data: lenet(data, dev_params[0])\n",
    "        test_acc = utils.evaluate_accuracy(test_data, net, ctx[0])\n",
    "        print('      validation accuray = %.4f' % (test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on [gpu(0)]\n",
      "Epoch 0, training time = 1.2 sec\n",
      "      validation accuray = 0.1000\n",
      "Epoch 1, training time = 0.9 sec\n",
      "      validation accuray = 0.1002\n",
      "Epoch 2, training time = 1.1 sec\n",
      "      validation accuray = 0.1002\n",
      "Epoch 3, training time = 0.8 sec\n",
      "      validation accuray = 0.1001\n",
      "Epoch 4, training time = 0.8 sec\n",
      "      validation accuray = 0.1001\n"
     ]
    }
   ],
   "source": [
    "train(1, 256, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on [gpu(0), cpu(0)]\n",
      "Epoch 0, training time = 18.9 sec\n",
      "      validation accuray = 0.6487\n",
      "Epoch 1, training time = 18.9 sec\n",
      "      validation accuray = 0.7831\n",
      "Epoch 2, training time = 18.8 sec\n",
      "      validation accuray = 0.7979\n",
      "Epoch 3, training time = 18.9 sec\n",
      "      validation accuray = 0.8086\n",
      "Epoch 4, training time = 19.0 sec\n",
      "      validation accuray = 0.8205\n"
     ]
    }
   ],
   "source": [
    "train(2, 256, 0.3)\n",
    "# CPU is too slow, so total time is slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on [gpu(0), cpu(0)]\n",
      "Epoch 0, training time = 18.8 sec\n",
      "      validation accuray = 0.0998\n",
      "Epoch 1, training time = 19.3 sec\n",
      "      validation accuray = 0.1007\n",
      "Epoch 2, training time = 19.2 sec\n",
      "      validation accuray = 0.1003\n",
      "Epoch 3, training time = 19.3 sec\n",
      "      validation accuray = 0.1009\n",
      "Epoch 4, training time = 19.3 sec\n",
      "      validation accuray = 0.1002\n"
     ]
    }
   ],
   "source": [
    "train(2, 512, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(3, 768, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
